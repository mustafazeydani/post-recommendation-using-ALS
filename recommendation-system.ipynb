{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee1b2104-56a7-4b64-aa99-8327f5c73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Environment variables for PySpark\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Collaborative Filtering-Based Recommendation System Pipeline\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
    "    .config(\"spark.driver.memory\", \"96g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.master\", \"local[12]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the datasets as Spark DataFrames\n",
    "posts_df = spark.read.csv('datasets/post_data.csv', header=True, inferSchema=True)\n",
    "views_df = spark.read.csv('datasets/view_data.csv', header=True, inferSchema=True)\n",
    "users_df = spark.read.csv('datasets/user_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c79aac",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing\n",
    "### 2.1. Generate Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6493d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------------+-----+\n",
      "|             user_id|  post_id|         time_stamp|score|\n",
      "+--------------------+---------+-------------------+-----+\n",
      "|5eece14ffc13ae660...|136781766|01/01/2019 01:30 PM|    2|\n",
      "|5eece14efc13ae660...| 43094523|01/01/2019 01:33 PM|    1|\n",
      "|5eece14efc13ae660...| 42428071|01/01/2019 01:43 PM|    1|\n",
      "|5eece14ffc13ae660...| 76472880|01/01/2019 01:54 PM|    2|\n",
      "|5eece14ffc13ae660...|202721843|01/01/2019 02:00 PM|    3|\n",
      "+--------------------+---------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random probabilities for scores 1, 2, and 3 using NumPy\n",
    "probs = np.random.dirichlet(np.ones(3))\n",
    "score_choices = [1, 2, 3]\n",
    "\n",
    "# Broadcast the probabilities and score choices\n",
    "probs_broadcast = spark.sparkContext.broadcast(probs)\n",
    "score_choices_broadcast = spark.sparkContext.broadcast(score_choices)\n",
    "\n",
    "# Define a UDF to assign scores based on probabilities\n",
    "def generate_score():\n",
    "    return int(np.random.choice(score_choices_broadcast.value, p=probs_broadcast.value))\n",
    "\n",
    "generate_score_udf = udf(generate_score, IntegerType())\n",
    "\n",
    "# Add the score column to the views_df DataFrame to create interactions_df\n",
    "interactions_df = views_df.withColumn(\"score\", generate_score_udf())\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "interactions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab58f4",
   "metadata": {},
   "source": [
    "### 2.2. Data Cleaning and Transformation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3da4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Select only the necessary columns [\"userId\", \"postId\", \"score\"]\n",
    "interactions_df = interactions_df.select(\"user_id\", \"post_id\", \"score\")\n",
    "\n",
    "# Remove duplicates from the interactions DataFrame\n",
    "interactions_df = interactions_df.dropDuplicates()\n",
    "\n",
    "# Use StringIndexer to convert 'user_id' to numeric value\n",
    "indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_id_numeric\")\n",
    "interactions_df = indexer.fit(interactions_df).transform(interactions_df)\n",
    "\n",
    "# Convert the 'score' column to double type\n",
    "interactions_df = interactions_df \\\n",
    "    .withColumn(\"score\", col(\"score\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a89c4",
   "metadata": {},
   "source": [
    "### 2.3. Splitting Data Into Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff9b177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, post_id: int, score: double, user_id_numeric: double]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the interactions DataFrame into 60% train, 20% validation, and 20% test\n",
    "train, validation, test = interactions_df.randomSplit([0.6, 0.2, 0.2], seed=99)\n",
    "\n",
    "# Cache the datasets\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8edf6",
   "metadata": {},
   "source": [
    "## 3. MODEL TRAINING AND EVALUATION\n",
    "### 3.1. ALS Hyperparameters Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d8245eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 latent factors and regularization = 0.01: validation RMSE is 0.8221641694902733\n",
      "5 latent factors and regularization = 0.05: validation RMSE is 0.6965556164880519\n",
      "5 latent factors and regularization = 0.1: validation RMSE is 0.6477020174140632\n",
      "5 latent factors and regularization = 0.2: validation RMSE is 0.6271705937318407\n",
      "5 latent factors and regularization = 0.5: validation RMSE is 0.7600068868467549\n",
      "10 latent factors and regularization = 0.01: validation RMSE is 1.4400833710348304\n",
      "10 latent factors and regularization = 0.05: validation RMSE is 0.7124231464332522\n",
      "10 latent factors and regularization = 0.1: validation RMSE is 0.6551823230759508\n",
      "10 latent factors and regularization = 0.2: validation RMSE is 0.6284981255634812\n",
      "10 latent factors and regularization = 0.5: validation RMSE is 0.760006882742498\n",
      "20 latent factors and regularization = 0.01: validation RMSE is 1.0386905703861409\n",
      "20 latent factors and regularization = 0.05: validation RMSE is 0.7087230879333094\n",
      "20 latent factors and regularization = 0.1: validation RMSE is 0.658014305683595\n",
      "20 latent factors and regularization = 0.2: validation RMSE is 0.62914585902535\n",
      "20 latent factors and regularization = 0.5: validation RMSE is 0.7600068905021312\n",
      "30 latent factors and regularization = 0.01: validation RMSE is 0.955528831380098\n",
      "30 latent factors and regularization = 0.05: validation RMSE is 0.7050955795152337\n",
      "30 latent factors and regularization = 0.1: validation RMSE is 0.6577935824223943\n",
      "30 latent factors and regularization = 0.2: validation RMSE is 0.6300098407305041\n",
      "30 latent factors and regularization = 0.5: validation RMSE is 0.7600068938989705\n",
      "40 latent factors and regularization = 0.01: validation RMSE is 0.9006096969364812\n",
      "40 latent factors and regularization = 0.05: validation RMSE is 0.7026170479014464\n",
      "40 latent factors and regularization = 0.1: validation RMSE is 0.65771672416355\n",
      "40 latent factors and regularization = 0.2: validation RMSE is 0.6302082153436804\n",
      "40 latent factors and regularization = 0.5: validation RMSE is 0.7600068853794884\n",
      "50 latent factors and regularization = 0.01: validation RMSE is 0.8848324972256649\n",
      "50 latent factors and regularization = 0.05: validation RMSE is 0.7008140551655949\n",
      "50 latent factors and regularization = 0.1: validation RMSE is 0.656815543038915\n",
      "50 latent factors and regularization = 0.2: validation RMSE is 0.6298622845960795\n",
      "50 latent factors and regularization = 0.5: validation RMSE is 0.7600068945078945\n",
      "\n",
      "The best model has 5 latent factors and regularization = 0.2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Function to tune the ALS model by finding the optimal rank and regularization parameters using the Grid Search technique\n",
    "def tune_ALS(train_data, validation_data, max_iters, regularization_params, ranks):\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    als = ALS(\n",
    "            userCol='user_id_numeric',\n",
    "            itemCol='post_id',\n",
    "            ratingCol='score',\n",
    "            coldStartStrategy=\"drop\")\n",
    "    \n",
    "    for rank in ranks:\n",
    "        for reg in regularization_params:\n",
    "            # get ALS model\n",
    "            als.setMaxIter(max_iters).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"score\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print('{} latent factors and regularization = {}: '\n",
    "                  'validation RMSE is {}'.format(rank, reg, rmse))\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    print('\\nThe best model has {} latent factors and '\n",
    "          'regularization = {}'.format(best_rank, best_regularization))\n",
    "    return best_model\n",
    "\n",
    "# Define the hyperparameters\n",
    "max_iters = 10\n",
    "regularization_params = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "ranks = [5, 10, 20, 30, 40, 50]\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "best_model = tune_ALS(train, validation, max_iters, regularization_params, ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
