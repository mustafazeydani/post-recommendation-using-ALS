{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ee1b2104-56a7-4b64-aa99-8327f5c73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# spark imports\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Environment variables for PySpark\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Collaborative Filtering-Based Recommendation System Pipeline\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"96g\") \\\n",
    "    .config(\"spark.driver.memory\", \"96g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.master\", \"local[12]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load the datasets as Spark DataFrames\n",
    "posts_df = spark.read.csv('datasets/post_data.csv', header=True, inferSchema=True)\n",
    "views_df = spark.read.csv('datasets/view_data.csv', header=True, inferSchema=True)\n",
    "users_df = spark.read.csv('datasets/user_data.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c79aac",
   "metadata": {},
   "source": [
    "## 2. Data Pre-processing\n",
    "### 2.1. Generate Score Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6493d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------------+-----+\n",
      "|             user_id|  post_id|         time_stamp|score|\n",
      "+--------------------+---------+-------------------+-----+\n",
      "|5eece14ffc13ae660...|136781766|01/01/2019 01:30 PM|    2|\n",
      "|5eece14efc13ae660...| 43094523|01/01/2019 01:33 PM|    1|\n",
      "|5eece14efc13ae660...| 42428071|01/01/2019 01:43 PM|    2|\n",
      "|5eece14ffc13ae660...| 76472880|01/01/2019 01:54 PM|    2|\n",
      "|5eece14ffc13ae660...|202721843|01/01/2019 02:00 PM|    2|\n",
      "+--------------------+---------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate random probabilities for scores 1, 2, and 3 using NumPy\n",
    "probs = np.random.dirichlet(np.ones(3))\n",
    "score_choices = [1, 2, 3]\n",
    "\n",
    "# Broadcast the probabilities and score choices\n",
    "probs_broadcast = spark.sparkContext.broadcast(probs)\n",
    "score_choices_broadcast = spark.sparkContext.broadcast(score_choices)\n",
    "\n",
    "# Define a UDF to assign scores based on probabilities\n",
    "def generate_score():\n",
    "    return int(np.random.choice(score_choices_broadcast.value, p=probs_broadcast.value))\n",
    "\n",
    "generate_score_udf = udf(generate_score, IntegerType())\n",
    "\n",
    "# Add the score column to the views_df DataFrame to create interactions_df\n",
    "interactions_df = views_df.withColumn(\"score\", generate_score_udf())\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "interactions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab58f4",
   "metadata": {},
   "source": [
    "### 2.2. Data Cleaning and Transformation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e3da4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Select only the necessary columns [\"userId\", \"postId\", \"score\"]\n",
    "interactions_df = interactions_df.select(\"user_id\", \"post_id\", \"score\")\n",
    "\n",
    "# Remove duplicates from the interactions DataFrame\n",
    "interactions_df = interactions_df.dropDuplicates()\n",
    "\n",
    "# Use StringIndexer to convert 'user_id' to numeric value\n",
    "indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_id_numeric\")\n",
    "interactions_df = indexer.fit(interactions_df).transform(interactions_df)\n",
    "\n",
    "# Convert the 'score' column to double type\n",
    "interactions_df = interactions_df \\\n",
    "    .withColumn(\"score\", col(\"score\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a89c4",
   "metadata": {},
   "source": [
    "### 2.3. Splitting Data Into Train, Validation and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff9b177f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[user_id: string, post_id: int, score: double, user_id_numeric: double]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the interactions DataFrame into 60% train, 20% validation, and 20% test\n",
    "train, validation, test = interactions_df.randomSplit([0.6, 0.2, 0.2], seed=99)\n",
    "\n",
    "# Cache the datasets\n",
    "train.cache()\n",
    "validation.cache()\n",
    "test.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc8edf6",
   "metadata": {},
   "source": [
    "## 3. MODEL TRAINING AND EVALUATION\n",
    "### 3.1. ALS Hyperparameters Tuning Using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d8245eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 5 and Regularization: 0.01 | Validation RMSE: 1.0051\n",
      "Rank: 5 and Regularization: 0.05 | Validation RMSE: 0.8579\n",
      "Rank: 5 and Regularization: 0.1 | Validation RMSE: 0.7930\n",
      "Rank: 5 and Regularization: 0.2 | Validation RMSE: 0.7548\n",
      "Rank: 5 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "Rank: 10 and Regularization: 0.01 | Validation RMSE: 1.8189\n",
      "Rank: 10 and Regularization: 0.05 | Validation RMSE: 0.8916\n",
      "Rank: 10 and Regularization: 0.1 | Validation RMSE: 0.8122\n",
      "Rank: 10 and Regularization: 0.2 | Validation RMSE: 0.7617\n",
      "Rank: 10 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "Rank: 20 and Regularization: 0.01 | Validation RMSE: 1.3729\n",
      "Rank: 20 and Regularization: 0.05 | Validation RMSE: 0.8812\n",
      "Rank: 20 and Regularization: 0.1 | Validation RMSE: 0.8119\n",
      "Rank: 20 and Regularization: 0.2 | Validation RMSE: 0.7635\n",
      "Rank: 20 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "Rank: 30 and Regularization: 0.01 | Validation RMSE: 1.2533\n",
      "Rank: 30 and Regularization: 0.05 | Validation RMSE: 0.8739\n",
      "Rank: 30 and Regularization: 0.1 | Validation RMSE: 0.8108\n",
      "Rank: 30 and Regularization: 0.2 | Validation RMSE: 0.7645\n",
      "Rank: 30 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "Rank: 40 and Regularization: 0.01 | Validation RMSE: 1.1571\n",
      "Rank: 40 and Regularization: 0.05 | Validation RMSE: 0.8731\n",
      "Rank: 40 and Regularization: 0.1 | Validation RMSE: 0.8123\n",
      "Rank: 40 and Regularization: 0.2 | Validation RMSE: 0.7654\n",
      "Rank: 40 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "Rank: 50 and Regularization: 0.01 | Validation RMSE: 1.1333\n",
      "Rank: 50 and Regularization: 0.05 | Validation RMSE: 0.8703\n",
      "Rank: 50 and Regularization: 0.1 | Validation RMSE: 0.8109\n",
      "Rank: 50 and Regularization: 0.2 | Validation RMSE: 0.7651\n",
      "Rank: 50 and Regularization: 0.5 | Validation RMSE: 0.8579\n",
      "\n",
      "Best Model: 5 latent factors with regularization: 0.2\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Function to tune the ALS model by finding the optimal rank and regularization parameters using the Grid Search technique\n",
    "def tune_ALS(train_data, validation_data, max_iters, regularization_params, ranks):\n",
    "    # initial\n",
    "    min_error = float('inf')\n",
    "    best_rank = -1\n",
    "    best_regularization = 0\n",
    "    best_model = None\n",
    "    als = ALS(\n",
    "            userCol='user_id_numeric',\n",
    "            itemCol='post_id',\n",
    "            ratingCol='score',\n",
    "            coldStartStrategy=\"drop\")\n",
    "    \n",
    "    for rank in ranks:\n",
    "        for reg in regularization_params:\n",
    "            # get ALS model\n",
    "            als.setMaxIter(max_iters).setRank(rank).setRegParam(reg)\n",
    "            # train ALS model\n",
    "            model = als.fit(train_data)\n",
    "            # evaluate the model by computing the RMSE on the validation data\n",
    "            predictions = model.transform(validation_data)\n",
    "            evaluator = RegressionEvaluator(metricName=\"rmse\",\n",
    "                                            labelCol=\"score\",\n",
    "                                            predictionCol=\"prediction\")\n",
    "            rmse = evaluator.evaluate(predictions)\n",
    "            print(f\"Rank: {rank} and Regularization: {reg} | Validation RMSE: {rmse:.4f}\")\n",
    "            if rmse < min_error:\n",
    "                min_error = rmse\n",
    "                best_rank = rank\n",
    "                best_regularization = reg\n",
    "                best_model = model\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_rank} latent factors with regularization: {best_regularization}\")\n",
    "    return best_model\n",
    "\n",
    "# Define the hyperparameters\n",
    "max_iters = 10\n",
    "regularization_params = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "ranks = [5, 10, 20, 30, 40, 50]\n",
    "\n",
    "# Start the hyperparameter tuning process\n",
    "best_model = tune_ALS(train, validation, max_iters, regularization_params, ranks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
